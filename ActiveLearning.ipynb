{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8429ad82-07df-4266-8bec-e389d027be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from see.Segment_Fitness import FitnessFunction, multi_value_ff\n",
    "from see.Segmentors import segmentor\n",
    "from see.ColorSpace import colorspace\n",
    "from see.Workflow import workflow\n",
    "from see.Segment_Fitness import segment_fitness\n",
    "from see import base_classes, GeneticSearch\n",
    "import copy\n",
    "import numpy as np\n",
    "#FitnessFunction(datas[3].mask,datas[1].mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7684b26-a9a8-4b32-8307-c6756a417612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GeneratePairs(size): #Generates each pair in a set\n",
    "    pairs=[]\n",
    "    for i in range(size):\n",
    "        for j in range(i+1,size):\n",
    "            pairs.append([i,j])\n",
    "    return pairs\n",
    "GeneratePairs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2a945d-de7a-4e4c-8a59-ef1dd741f2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.UncertaintyValue(segmenters, data)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def UncertaintyValue(segmenters,data): #Compute uncertainty value\n",
    "    #Generate N copies of image\n",
    "    dataCopies=[copy.deepcopy(data) for i in range(len(segmenters))]\n",
    "\n",
    "    #Create segmenters\n",
    "    segs=[workflow(i) for i in segmenters]\n",
    "\n",
    "    #Run each segmenter on a copy of an image\n",
    "    dataCopies=[segs[i].runAlgo(dataCopies[i]) for i in range(len(segs))]\n",
    "\n",
    "    #Return the mean difference between each pairwise prediction\n",
    "    uncertainty=mean([FitnessFunction(dataCopies[i[0]],dataCopies[i[1]]) for i in GeneratePairs(len(dataCopies))])\n",
    "    return uncertainty\n",
    "\n",
    "UncertaintyValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30a3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALSearch(segmenters,dataSet): #Search data set for image with highest uncertainty value\n",
    "    #Generate uncertainty value for each image\n",
    "    uncertainties=[UncertaintyValue(segmenters,data) for data in dataSet]\n",
    "\n",
    "    #Return copy of image with most uncertainty (should this be argmax?)\n",
    "    return np.argmin(uncertainties) #copy.deepcopy(dataSet[np.argmin(uncertainties)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9610f98b-589f-43b3-bd2e-e72a43e95aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ActiveLearning(trainingDataSet,testData,iterations=10):\n",
    "    #Initialize selected training set and fitness tracking\n",
    "    selectedTrainSet=[]\n",
    "    testFitness=[]\n",
    "    best=[]\n",
    "\n",
    "    #Copy training set to unselected set\n",
    "    unselectedTrainingData=copy.deepcopy(trainingDataSet)\n",
    "\n",
    "    #Select a single image from training set to initialize active training set and remove from unselected set\n",
    "    selectedInt=np.random.randint(0,len(unselectedTrainingData))\n",
    "    selectedTrainSet.append(unselectedTrainingData[selectedInt])\n",
    "    del unselectedTrainingData[selectedInt]\n",
    "\n",
    "    #Define workflow and initialize evolver\n",
    "    workflow.addalgos([colorspace, segmentor, segment_fitness])\n",
    "    my_evolver = GeneticSearch.Evolver(workflow, selectedTrainSet, pop_size=100)\n",
    "\n",
    "    #Begin loop over active learning iterations\n",
    "    for i in range(iterations): \n",
    "        #Execute first round of evolution ??How do you modify the training data??\n",
    "        population = my_evolver.run(ngen=10)\n",
    "\n",
    "        #Generate model ensemble from quality models in the population (HoF)\n",
    "        ensemble=[]\n",
    "        ensemble=my_evolver.hof[:min(10,len(my_evolver.hof))]\n",
    "\n",
    "        #Use ALSearch to maximize uncertainty over unselected training set\n",
    "        selectedImage=ALSearch(ensemble,unselectedTrainingData)\n",
    "        \n",
    "\n",
    "        #Add new sample to training set and remove from unselected\n",
    "        selectedTrainSet.append(unselectedTrainingData[selectedImage])\n",
    "        del unselectedTrainingData[selectedImage]\n",
    "\n",
    "        #Update evolver with new data\n",
    "        my_evolver.updateData(selectedTrainSet)\n",
    "\n",
    "        #Record current best performance on test data and append to tracking list\n",
    "        tData=copy.deepcopy(testData)\n",
    "        seg=workflow(my_evolver.hof[0])\n",
    "        tData=seg.runAlgo(tData)\n",
    "        bestFitness=multi_value_ff(tData)\n",
    "        testFitness.append(bestFitness)\n",
    "        \n",
    "\n",
    "    #Return best model found, best fitness found, and fitness list\n",
    "    return best, bestFitness, testFitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f497120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./Image_Data/KOMATSUNA/  Created \n",
      "Downloading rgbd_plant.zip from http://limu.ait.kyushu-u.ac.jp/~agri/komatsuna/rgbd_plant.zip\n",
      "Unzipping rgbd_plant.zip\n",
      "Download and Convert of rgbd_plant.zip Complete\n",
      "Downloading rgbd_label.zip from http://limu.ait.kyushu-u.ac.jp/~agri/komatsuna/rgbd_label.zip\n",
      "Unzipping rgbd_label.zip\n",
      "Download and Convert of rgbd_label.zip Complete\n"
     ]
    }
   ],
   "source": [
    "#The following code will download the dataset to the Images_Data folder\n",
    "from see import DataDownload as dd\n",
    "\n",
    "dd.downloadKOMATSUNA(folder='./Image_Data/KOMATSUNA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec7f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import v3 as imageio\n",
    "\n",
    "img1 = imageio.imread('Image_data/KOMATSUNA/rgbd_plant/rgb_00_000_00.png')\n",
    "gmask1 = imageio.imread('Image_data/KOMATSUNA/rgbd_label/label_00_000_00.png')\n",
    "\n",
    "img2 = imageio.imread('Image_data/KOMATSUNA/rgbd_plant/rgb_00_000_01.png')\n",
    "gmask2 = imageio.imread('Image_data/KOMATSUNA/rgbd_label/label_00_000_01.png')\n",
    "\n",
    "img3 = imageio.imread('Image_data/KOMATSUNA/rgbd_plant/rgb_00_000_02.png')\n",
    "gmask3 = imageio.imread('Image_data/KOMATSUNA/rgbd_label/label_00_000_02.png')\n",
    "\n",
    "img4 = imageio.imread('Image_data/KOMATSUNA/rgbd_plant/rgb_00_000_03.png')\n",
    "gmask4 = imageio.imread('Image_data/KOMATSUNA/rgbd_label/label_00_000_03.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230018f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from see import base_classes\n",
    "\n",
    "# put data in a pipeline\n",
    "mydata = base_classes.pipedata()\n",
    "mydata.append(img1)\n",
    "mydata.append(img2)\n",
    "mydata.append(img3)\n",
    "mydata.append(img4)\n",
    "mydata.gtruth = []\n",
    "mydata.gtruth.append(gmask1)\n",
    "mydata.gtruth.append(gmask2)\n",
    "mydata.gtruth.append(gmask3)\n",
    "mydata.gtruth.append(gmask4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248b461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing a new random population\n",
      "Generation 0/10 of population size 100\n",
      "<class 'see.Workflow.workflow'> parameters: \n",
      "\tcolorspace = YIQ\n",
      "\tmultichannel = False\n",
      "\tchannel = 1\n",
      "\talgorithm = Chan_Vese\n",
      "\talpha1 = 0.375\n",
      "\talpha2 = 0.6875\n",
      "\tbeta1 = 0.46875\n",
      "\tbeta2 = 0.47265625\n",
      "\tgamma1 = 0.703125\n",
      "\tgamma2 = 0.14453125\n",
      "\tn_segments = 4\n",
      "\tmax_num_iter = 19\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output\u001b[39m=\u001b[39mActiveLearning(mydata, mydata, iterations\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m, in \u001b[0;36mActiveLearning\u001b[0;34m(trainingDataSet, testData, iterations)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m#Begin loop over active learning iterations\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations): \n\u001b[1;32m     21\u001b[0m     \u001b[39m#Execute first round of evolution ??How do you modify the training data??\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     population \u001b[39m=\u001b[39m my_evolver\u001b[39m.\u001b[39;49mrun(ngen\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m     \u001b[39m#Generate model ensemble from quality models in the population (HoF)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     ensemble\u001b[39m=\u001b[39m[]\n",
      "File \u001b[0;32m~/Documents/GitHub/see-segment/see/GeneticSearch.py:505\u001b[0m, in \u001b[0;36mEvolver.run\u001b[0;34m(self, ngen, population, startfile, checkpoint, cp_freq, print_raw_data)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mfor\u001b[39;00m cur_g \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, ngen \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    503\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGeneration \u001b[39m\u001b[39m{\u001b[39;00mcur_g\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mngen\u001b[39m}\u001b[39;00m\u001b[39m of population size \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(population)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m     _, population \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopfitness(population)\n\u001b[1;32m    507\u001b[0m     bestsofar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhof[\u001b[39m0\u001b[39m]\n\u001b[1;32m    509\u001b[0m     \u001b[39m# Create a new instance from the current algorithm\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39m# seg = self.algo_constructor(bestsofar)\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39m# self.data = seg.pipe(self.data)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/see-segment/see/GeneticSearch.py:354\u001b[0m, in \u001b[0;36mEvolver.popfitness\u001b[0;34m(self, tpop)\u001b[0m\n\u001b[1;32m    350\u001b[0m outdata \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtool\u001b[39m.\u001b[39mevaluate, algos, data_references)\n\u001b[1;32m    352\u001b[0m \u001b[39m# Loop though outputs and add them to ind.fitness so we have a complete\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m# record.\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[39mfor\u001b[39;00m ind, data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tpop, outdata):\n\u001b[1;32m    355\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfitness=\u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mfitness\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m     ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalues \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mfitness]\n",
      "File \u001b[0;32m~/Documents/GitHub/see-segment/see/base_classes.py:163\u001b[0m, in \u001b[0;36malgorithm.runAlgo\u001b[0;34m(self, data, params)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipe(data)\n\u001b[1;32m    164\u001b[0m     endTime \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m{\u001b[39;00m(endTime\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstartTime)\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m s\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/see-segment/see/Workflow.py:43\u001b[0m, in \u001b[0;36mworkflow.pipe\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     41\u001b[0m     algo \u001b[39m=\u001b[39m algo_constructor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     42\u001b[0m     algo\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39maddall(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m---> 43\u001b[0m     data \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39;49mpipe(data)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/GitHub/see-segment/see/ColorSpace.py:115\u001b[0m, in \u001b[0;36mcolorspace.pipe\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set inputimage and img to evaluated data images.\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[0;32m--> 115\u001b[0m     data[i]\u001b[39m.\u001b[39;49mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(data[i][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m    116\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "output=ActiveLearning(mydata, mydata, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b5705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
